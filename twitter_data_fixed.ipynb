{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the modules\n",
    "import os\n",
    "import time\n",
    "import datetime as DT\n",
    "import tweepy\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from opencage.geocoder import OpenCageGeocode\n",
    "import functools\n",
    "def conjunction(*conditions):\n",
    "    return functools.reduce(np.logical_and, conditions)\n",
    "def DT_from_utc_to_local(utc_datetime):\n",
    "    now_timestamp = time.time()\n",
    "    offset = DT.datetime.fromtimestamp(now_timestamp) - DT.datetime.utcfromtimestamp(now_timestamp)\n",
    "    return utc_datetime + offset\n",
    "\n",
    "# Load credentials from json file:\n",
    "os.chdir(r\"/Users/macbook/Desktop/Data-Program-Files/Group-Projects/Project-3/\") #Folder Location\n",
    "with open(\"twitter_credentials.json\", \"r\") as file:\n",
    "    creds = json.load(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set up Twitter Authentication\n",
    "auth = tweepy.OAuthHandler(creds['CONSUMER_KEY'], creds['CONSUMER_SECRET'])\n",
    "auth.set_access_token(creds['ACCESS_TOKEN'], creds['ACCESS_SECRET'])\n",
    "api = tweepy.API(auth)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Begin API Scrape - Day 1\n",
    "listTweets1 = []\n",
    "\n",
    "today = DT.date.today()\n",
    "StartDt = today - DT.timedelta(days=7)\n",
    "EndDt = DT.date.today() - DT.timedelta(days=6)\n",
    "searchterm = '#feelthebern'\n",
    "keyword = searchterm+' since:'+str(StartDt)+' until:'+str(EndDt)+' -filter:retweets'\n",
    "NumTweets = 200\n",
    "\n",
    "def get_tweets1(listTweets1, keyword, NumTweets):\n",
    "    # Iterate through all tweets containing the given word, api search mode\n",
    "    for tweet in tweepy.Cursor(api.search, q=keyword).items(NumTweets):\n",
    "        # Add tweets in this format\n",
    "        dict_ = {'Screen_Name': tweet.user.screen_name,\n",
    "                'User_Name': tweet.user.name,\n",
    "                'Tweet_Created_At': str(DT_from_utc_to_local(tweet.created_at)),\n",
    "                'Tweet_Text': tweet.text,\n",
    "                'Hashtags': tweet.entities.get('hashtags'), #How? - get only hashtag text\n",
    "                'User_Location': str(tweet.user.location),\n",
    "                'Tweet_Coordinates': str(tweet.coordinates),\n",
    "                'Tweet_Place': str(tweet.place),\n",
    "                'Retweet_Count': str(tweet.retweet_count),\n",
    "                'Retweeted': str(tweet.retweeted),\n",
    "                'Favorite_Count': str(tweet.favorite_count),\n",
    "                'Favorited': str(tweet.favorited),\n",
    "                'Replied': str(tweet.in_reply_to_status_id_str),\n",
    "                'Tweet_URL': tweet.entities.get('urls') #How? - get only expanded url?\n",
    "                }\n",
    "        listTweets1.append(dict_)   \n",
    "    return listTweets1\n",
    "\n",
    "get_tweets1(listTweets1, keyword, NumTweets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame.from_dict(listTweets1, orient='columns')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Begin API Scrape - Day 2\n",
    "listTweets2 = []\n",
    "\n",
    "StartDt = today - DT.timedelta(days=6)\n",
    "EndDt = DT.date.today() - DT.timedelta(days=5)\n",
    "searchterm = '#feelthebern'\n",
    "keyword = searchterm+' since:'+str(StartDt)+' until:'+str(EndDt)+' -filter:retweets'\n",
    "NumTweets = 200\n",
    "\n",
    "def get_tweets2(listTweets2, keyword, NumTweets):\n",
    "    # Iterate through all tweets containing the given word, api search mode\n",
    "    for tweet in tweepy.Cursor(api.search, q=keyword).items(NumTweets):\n",
    "        # Add tweets in this format\n",
    "        dict_ = {'Screen_Name': tweet.user.screen_name,\n",
    "                'User_Name': tweet.user.name,\n",
    "                'Tweet_Created_At': str(DT_from_utc_to_local(tweet.created_at)),\n",
    "                'Tweet_Text': tweet.text,\n",
    "                'Hashtags': tweet.entities.get('hashtags'), #How? - get only hashtag text\n",
    "                'User_Location': str(tweet.user.location),\n",
    "                'Tweet_Coordinates': str(tweet.coordinates),\n",
    "                'Tweet_Place': str(tweet.place),\n",
    "                'Retweet_Count': str(tweet.retweet_count),\n",
    "                'Retweeted': str(tweet.retweeted),\n",
    "                'Favorite_Count': str(tweet.favorite_count),\n",
    "                'Favorited': str(tweet.favorited),\n",
    "                'Replied': str(tweet.in_reply_to_status_id_str),\n",
    "                'Tweet_URL': tweet.entities.get('urls') #How? - get only expanded url?\n",
    "                }\n",
    "        listTweets2.append(dict_)   \n",
    "    return listTweets2\n",
    "\n",
    "get_tweets2(listTweets2, keyword, NumTweets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame.from_dict(listTweets2, orient='columns')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Begin API Scrape - Day 3\n",
    "listTweets3 = []\n",
    "\n",
    "StartDt = today - DT.timedelta(days=5)\n",
    "EndDt = DT.date.today() - DT.timedelta(days=4)\n",
    "searchterm = '#feelthebern'\n",
    "keyword = searchterm+' since:'+str(StartDt)+' until:'+str(EndDt)+' -filter:retweets'\n",
    "NumTweets = 200\n",
    "\n",
    "def get_tweets3(listTweets3, keyword, NumTweets):\n",
    "    # Iterate through all tweets containing the given word, api search mode\n",
    "    for tweet in tweepy.Cursor(api.search, q=keyword).items(NumTweets):\n",
    "        # Add tweets in this format\n",
    "        dict_ = {'Screen_Name': tweet.user.screen_name,\n",
    "                'User_Name': tweet.user.name,\n",
    "                'Tweet_Created_At': str(DT_from_utc_to_local(tweet.created_at)),\n",
    "                'Tweet_Text': tweet.text,\n",
    "                'Hashtags': tweet.entities.get('hashtags'), #How? - get only hashtag text\n",
    "                'User_Location': str(tweet.user.location),\n",
    "                'Tweet_Coordinates': str(tweet.coordinates),\n",
    "                'Tweet_Place': str(tweet.place),\n",
    "                'Retweet_Count': str(tweet.retweet_count),\n",
    "                'Retweeted': str(tweet.retweeted),\n",
    "                'Favorite_Count': str(tweet.favorite_count),\n",
    "                'Favorited': str(tweet.favorited),\n",
    "                'Replied': str(tweet.in_reply_to_status_id_str),\n",
    "                'Tweet_URL': tweet.entities.get('urls') #How? - get only expanded url?\n",
    "                }\n",
    "        listTweets3.append(dict_)   \n",
    "    return listTweets3\n",
    "\n",
    "get_tweets3(listTweets3, keyword, NumTweets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.DataFrame.from_dict(listTweets3, orient='columns')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Begin API Scrape - Day 4\n",
    "listTweets4 = []\n",
    "\n",
    "StartDt = today - DT.timedelta(days=4)\n",
    "EndDt = DT.date.today() - DT.timedelta(days=3)\n",
    "searchterm = '#feelthebern'\n",
    "keyword = searchterm+' since:'+str(StartDt)+' until:'+str(EndDt)+' -filter:retweets'\n",
    "NumTweets = 200\n",
    "\n",
    "def get_tweets4(listTweets4, keyword, NumTweets):\n",
    "    # Iterate through all tweets containing the given word, api search mode\n",
    "    for tweet in tweepy.Cursor(api.search, q=keyword).items(NumTweets):\n",
    "        # Add tweets in this format\n",
    "        dict_ = {'Screen_Name': tweet.user.screen_name,\n",
    "                'User_Name': tweet.user.name,\n",
    "                'Tweet_Created_At': str(DT_from_utc_to_local(tweet.created_at)),\n",
    "                'Tweet_Text': tweet.text,\n",
    "                'Hashtags': tweet.entities.get('hashtags'), #How? - get only hashtag text\n",
    "                'User_Location': str(tweet.user.location),\n",
    "                'Tweet_Coordinates': str(tweet.coordinates),\n",
    "                'Tweet_Place': str(tweet.place),\n",
    "                'Retweet_Count': str(tweet.retweet_count),\n",
    "                'Retweeted': str(tweet.retweeted),\n",
    "                'Favorite_Count': str(tweet.favorite_count),\n",
    "                'Favorited': str(tweet.favorited),\n",
    "                'Replied': str(tweet.in_reply_to_status_id_str),\n",
    "                'Tweet_URL': tweet.entities.get('urls') #How? - get only expanded url?\n",
    "                }\n",
    "        listTweets4.append(dict_)   \n",
    "    return listTweets4\n",
    "\n",
    "get_tweets4(listTweets4, keyword, NumTweets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = pd.DataFrame.from_dict(listTweets4, orient='columns')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Begin API Scrape - Day 5\n",
    "listTweets5 = []\n",
    "\n",
    "StartDt = today - DT.timedelta(days=3)\n",
    "EndDt = DT.date.today() - DT.timedelta(days=2)\n",
    "searchterm = '#feelthebern'\n",
    "keyword = searchterm+' since:'+str(StartDt)+' until:'+str(EndDt)+' -filter:retweets'\n",
    "NumTweets = 200\n",
    "\n",
    "def get_tweets5(listTweets5, keyword, NumTweets):\n",
    "    # Iterate through all tweets containing the given word, api search mode\n",
    "    for tweet in tweepy.Cursor(api.search, q=keyword).items(NumTweets):\n",
    "        # Add tweets in this format\n",
    "        dict_ = {'Screen_Name': tweet.user.screen_name,\n",
    "                'User_Name': tweet.user.name,\n",
    "                'Tweet_Created_At': str(DT_from_utc_to_local(tweet.created_at)),\n",
    "                'Tweet_Text': tweet.text,\n",
    "                'Hashtags': tweet.entities.get('hashtags'), #How? - get only hashtag text\n",
    "                'User_Location': str(tweet.user.location),\n",
    "                'Tweet_Coordinates': str(tweet.coordinates),\n",
    "                'Tweet_Place': str(tweet.place),\n",
    "                'Retweet_Count': str(tweet.retweet_count),\n",
    "                'Retweeted': str(tweet.retweeted),\n",
    "                'Favorite_Count': str(tweet.favorite_count),\n",
    "                'Favorited': str(tweet.favorited),\n",
    "                'Replied': str(tweet.in_reply_to_status_id_str),\n",
    "                'Tweet_URL': tweet.entities.get('urls') #How? - get only expanded url?\n",
    "                }\n",
    "        listTweets5.append(dict_)   \n",
    "    return listTweets5\n",
    "\n",
    "get_tweets5(listTweets5, keyword, NumTweets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5 = pd.DataFrame.from_dict(listTweets5, orient='columns')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Begin API Scrape - Day 6\n",
    "listTweets6 = []\n",
    "\n",
    "StartDt = today - DT.timedelta(days=2)\n",
    "EndDt = DT.date.today() - DT.timedelta(days=1)\n",
    "searchterm = '#feelthebern'\n",
    "keyword = searchterm+' since:'+str(StartDt)+' until:'+str(EndDt)+' -filter:retweets'\n",
    "NumTweets = 200\n",
    "\n",
    "def get_tweets6(listTweets6, keyword, NumTweets):\n",
    "    # Iterate through all tweets containing the given word, api search mode\n",
    "    for tweet in tweepy.Cursor(api.search, q=keyword).items(NumTweets):\n",
    "        # Add tweets in this format\n",
    "        dict_ = {'Screen_Name': tweet.user.screen_name,\n",
    "                'User_Name': tweet.user.name,\n",
    "                'Tweet_Created_At': str(DT_from_utc_to_local(tweet.created_at)),\n",
    "                'Tweet_Text': tweet.text,\n",
    "                'Hashtags': tweet.entities.get('hashtags'), #How? - get only hashtag text\n",
    "                'User_Location': str(tweet.user.location),\n",
    "                'Tweet_Coordinates': str(tweet.coordinates),\n",
    "                'Tweet_Place': str(tweet.place),\n",
    "                'Retweet_Count': str(tweet.retweet_count),\n",
    "                'Retweeted': str(tweet.retweeted),\n",
    "                'Favorite_Count': str(tweet.favorite_count),\n",
    "                'Favorited': str(tweet.favorited),\n",
    "                'Replied': str(tweet.in_reply_to_status_id_str),\n",
    "                'Tweet_URL': tweet.entities.get('urls') #How? - get only expanded url?\n",
    "                }\n",
    "        listTweets6.append(dict_)   \n",
    "    return listTweets6\n",
    "\n",
    "get_tweets6(listTweets6, keyword, NumTweets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df6 = pd.DataFrame.from_dict(listTweets6, orient='columns')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Begin API Scrape - Day 7\n",
    "listTweets7 = []\n",
    "\n",
    "StartDt = today - DT.timedelta(days=1)\n",
    "EndDt = DT.date.today() - DT.timedelta(days=0)\n",
    "searchterm = '#feelthebern'\n",
    "keyword = searchterm+' since:'+str(StartDt)+' until:'+str(EndDt)+' -filter:retweets'\n",
    "NumTweets = 200\n",
    "\n",
    "def get_tweets7(listTweets7, keyword, NumTweets):\n",
    "    # Iterate through all tweets containing the given word, api search mode\n",
    "    for tweet in tweepy.Cursor(api.search, q=keyword).items(NumTweets):\n",
    "        # Add tweets in this format\n",
    "        dict_ = {'Screen_Name': tweet.user.screen_name,\n",
    "                'User_Name': tweet.user.name,\n",
    "                'Tweet_Created_At': str(DT_from_utc_to_local(tweet.created_at)),\n",
    "                'Tweet_Text': tweet.text,\n",
    "                'Hashtags': tweet.entities.get('hashtags'), #How? - get only hashtag text\n",
    "                'User_Location': str(tweet.user.location),\n",
    "                'Tweet_Coordinates': str(tweet.coordinates),\n",
    "                'Tweet_Place': str(tweet.place),\n",
    "                'Retweet_Count': str(tweet.retweet_count),\n",
    "                'Retweeted': str(tweet.retweeted),\n",
    "                'Favorite_Count': str(tweet.favorite_count),\n",
    "                'Favorited': str(tweet.favorited),\n",
    "                'Replied': str(tweet.in_reply_to_status_id_str),\n",
    "                'Tweet_URL': tweet.entities.get('urls') #How? - get only expanded url?\n",
    "                }\n",
    "        listTweets7.append(dict_)   \n",
    "    return listTweets7\n",
    "\n",
    "get_tweets7(listTweets7, keyword, NumTweets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df7 = pd.DataFrame.from_dict(listTweets7, orient='columns')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_data = pd.concat([df1, df2, df3, df4, df5, df6, df7], axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add city coordinates to dataset\n",
    "key = creds['key']\n",
    "geocoder = OpenCageGeocode(key)\n",
    "\n",
    "location = twitter_data[['User_Location']].drop_duplicates()\n",
    "location = location.reset_index()\n",
    "Var_Empty = location['User_Location'] != ''\n",
    "location = location[conjunction(Var_Empty)]\n",
    "#Begin getting coordinates\n",
    "list_lat = []\n",
    "list_long = []\n",
    "for index, row in location.iterrows():\n",
    "    try:\n",
    "        city = row['User_Location']\n",
    "        query = str(city)\n",
    "        results = geocoder.geocode(query)\n",
    "        lat = results[0]['geometry']['lat']\n",
    "        long = results[0]['geometry']['lng']\n",
    "        list_lat.append(lat)\n",
    "        list_long.append(long)\n",
    "    except:\n",
    "        list_lat.append(0)\n",
    "        list_long.append(0)\n",
    "\n",
    "location['lat'] = list_lat\n",
    "location['long'] = list_long\n",
    "twitter_data = twitter_data.merge(location, left_on='User_Location', right_on='User_Location')\n",
    "twitter_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Var_0 = twitter_data['lat'] != 0\n",
    "twitter_data = twitter_data[conjunction(Var_0)]\n",
    "Twitter_data = twitter_data[['Screen_Name','User_Name','Tweet_Text','Hashtags','Tweet_Created_At','Favorite_Count','Retweet_Count','Tweet_URL','lat','long']]\n",
    "twitter_data['keyword'] = searchterm\n",
    "records = json.loads(twitter_data.T.to_json()).values()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connect to Mongo DB Atlas\n",
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "\n",
    "client = pymongo.MongoClient(\"mongodb+srv://vgalst:akopova123@tweetering-giclm.mongodb.net/test?retryWrites=true&w=majority\")\n",
    "db = client.twitter\n",
    "collection = db['hashtagdata']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection.insert_many(records)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#twitter_data = pd.read_csv(\"export_dataframe_4.csv\") \n",
    "#export_csv = twitter_data.to_csv (r'/Users/macbook/Desktop/Data-Program-Files/Group-Projects/Project-3/export_dataframe_4.csv', index = None, header=True) #Don't forget to add '.csv' at the end of the path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
